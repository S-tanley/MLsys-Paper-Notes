# GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding

## Context

**Abstract**:

Current problem: the computation cost, ease of programming, and efficient implementation on parallel devices

GShard provides an elegant way to express a wide range of parallel computation patterns with minimal changes to the existing model code.

**1. Introduction**

Bigger model performance is better, and need more computation.



**7. Conclusion**:

GShard provided an easy way for models to scale up.

Help people with the parallelization implementation.

Help partition the model.

## Notes



[^1]: Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen. 2020. GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding. [https://doi.org/10.48550/arXiv.2006.16668](https://urldefense.com/v3/__https:/doi.org/10.48550/arXiv.2006.16668__;!!Mak6IKo!JGsmunK4816F9qTIzFh0QAl_Tgr55CX5aR2IjjIRrsDaJvPzsI_qdQNouSpg-XfJEGex1dhRSBnoetBlo5Cl9Q$)